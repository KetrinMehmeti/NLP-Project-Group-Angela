{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-wL9uiR8v1Y"
      },
      "source": [
        "# BioBERT-based model to classify biomedical QA pairs into yes/no/maybe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF-N-uy88_UI"
      },
      "source": [
        "Two-stage pipeline:\n",
        "  1. Fine-tune BioBERT on labeled + (weighted) artificial data.\n",
        "  2. Evaluate model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8zQ1sd22r2d"
      },
      "source": [
        "## Importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5LB_RWNX2lRQ",
        "outputId": "2a479877-4b1f-4e03-e7b3-4bfc09de0b89"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ASUS\\Desktop\\Progetto\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the labeled, unlabeled, and artificial subsets of PubMedQA\n",
        "# The dataset is split into three subsets:\n",
        "\n",
        "dataset_labeled = load_dataset(\"qiaojin/PubMedQA\", 'pqa_labeled')\n",
        "dataset_unlabeled = load_dataset(\"qiaojin/PubMedQA\", 'pqa_unlabeled')\n",
        "dataset_artificial = load_dataset('qiaojin/PubMedQA', 'pqa_artificial')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vqYmkw5Y3YyT"
      },
      "outputs": [],
      "source": [
        "# Convert the datasets to pandas DataFrames for easier manipulation\n",
        "import pandas as pd\n",
        "\n",
        "df_labeled_original = pd.DataFrame(dataset_labeled['train'])\n",
        "df_unlabeled_original = pd.DataFrame(dataset_unlabeled['train'])\n",
        "df_artificial_original = pd.DataFrame(dataset_artificial['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "f8GZ83hV3dDx"
      },
      "outputs": [],
      "source": [
        "# Make a copy of the original datasets to work on\n",
        "df_labeled = df_labeled_original.copy()\n",
        "df_unlabeled = df_unlabeled_original.copy()\n",
        "df_artificial = df_artificial_original.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2epl7FVv38c-"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6pq0FcwU3_Mz"
      },
      "outputs": [],
      "source": [
        "# Function to merge Question and Contexts into Input\n",
        "def merge_fields(row):\n",
        "    context_text = \" \".join(row['context']['contexts'])\n",
        "    return f\"{context_text}\"\n",
        "\n",
        "# Apply function to all datasets\n",
        "for df in [df_labeled, df_artificial, df_unlabeled]:\n",
        "    df['context_str'] = df.apply(merge_fields, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qQdlnKQY9a_3"
      },
      "outputs": [],
      "source": [
        "df_labeled = df_labeled[df_labeled['final_decision'] != \"maybe\"]\n",
        "\n",
        "label_map = {'yes': 0, 'no': 1}\n",
        "df_labeled['label'] = df_labeled['final_decision'].map(label_map)\n",
        "df_artificial['label'] = df_artificial['final_decision'].map(label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_Z_zo3jQVZ-o"
      },
      "outputs": [],
      "source": [
        "df_labeled_final = df_labeled[['question','context_str', 'label']]\n",
        "df_artificial_final = df_artificial[['question','context_str', 'label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYdouJNJVheE",
        "outputId": "c5c222a0-887d-4bf7-9c28-e9fd03fce3a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "0    552\n",
            "1    338\n",
            "Name: count, dtype: int64\n",
            "label\n",
            "0    196144\n",
            "1     15125\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check class distribution\n",
        "print(df_labeled_final['label'].value_counts())\n",
        "print(df_artificial_final['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YZFDDLsiWRXS"
      },
      "outputs": [],
      "source": [
        "# Balance Artificial Dataset (Downsampling)\n",
        "df_artificial_final = df_artificial_final.groupby('label').sample(n=min(df_artificial_final['label'].value_counts()), random_state=42)\n",
        "# Shuffle the dataset\n",
        "df_artificial_final = df_artificial_final.sample(frac=1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMwFMRXs1EEW",
        "outputId": "161524ee-f832-41d1-9bea-7f233e71ef32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30250"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df_artificial_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7jsLSyKhXMin",
        "outputId": "815c6faf-f74c-4a4f-ee61-f6ce576680cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>context_str</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>117741</th>\n",
              "      <td>Are common genetic variants in the microRNA bi...</td>\n",
              "      <td>Although the role of miRNA in cancer developme...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164514</th>\n",
              "      <td>Do y-SNPs indicate hybridisation between Europ...</td>\n",
              "      <td>Previous genetic studies of modern and ancient...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178755</th>\n",
              "      <td>Is genetic polymorphisms ofCYP2A6 andCYP2E1 wi...</td>\n",
              "      <td>To elucidate the association between genetic p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51724</th>\n",
              "      <td>Does a background infusion of morphine enhance...</td>\n",
              "      <td>To compare the effects of patient-controlled a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67278</th>\n",
              "      <td>Do neutrophils promote aerogenous spread of lu...</td>\n",
              "      <td>Adenocarcinoma with bronchioloalveolar carcino...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 question  \\\n",
              "117741  Are common genetic variants in the microRNA bi...   \n",
              "164514  Do y-SNPs indicate hybridisation between Europ...   \n",
              "178755  Is genetic polymorphisms ofCYP2A6 andCYP2E1 wi...   \n",
              "51724   Does a background infusion of morphine enhance...   \n",
              "67278   Do neutrophils promote aerogenous spread of lu...   \n",
              "\n",
              "                                              context_str  label  \n",
              "117741  Although the role of miRNA in cancer developme...      1  \n",
              "164514  Previous genetic studies of modern and ancient...      1  \n",
              "178755  To elucidate the association between genetic p...      1  \n",
              "51724   To compare the effects of patient-controlled a...      1  \n",
              "67278   Adenocarcinoma with bronchioloalveolar carcino...      0  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train = df_artificial_final\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp4VwQoY2fSz",
        "outputId": "5182c48b-876d-4ded-841b-bd423e17f663"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "697"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df_train['context_str'].iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dabzQA7eY5Qh",
        "outputId": "51225399-0c38-4b9e-a5bc-0291ba52f383"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>context_str</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Do mitochondria play a role in remodelling lac...</td>\n",
              "      <td>Programmed cell death (PCD) is the regulated d...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Landolt C and snellen e acuity: differences in...</td>\n",
              "      <td>Assessment of visual acuity depends on the opt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Syncope during bathing in infants, a pediatric...</td>\n",
              "      <td>Apparent life-threatening events in infants ar...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Are the long-term results of the transanal pul...</td>\n",
              "      <td>The transanal endorectal pull-through (TERPT) ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Can tailored interventions increase mammograph...</td>\n",
              "      <td>Telephone counseling and tailored print commun...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  Do mitochondria play a role in remodelling lac...   \n",
              "1  Landolt C and snellen e acuity: differences in...   \n",
              "2  Syncope during bathing in infants, a pediatric...   \n",
              "3  Are the long-term results of the transanal pul...   \n",
              "4  Can tailored interventions increase mammograph...   \n",
              "\n",
              "                                         context_str  label  \n",
              "0  Programmed cell death (PCD) is the regulated d...      0  \n",
              "1  Assessment of visual acuity depends on the opt...      1  \n",
              "2  Apparent life-threatening events in infants ar...      0  \n",
              "3  The transanal endorectal pull-through (TERPT) ...      1  \n",
              "4  Telephone counseling and tailored print commun...      0  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test = df_labeled_final\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrHfGj485k18"
      },
      "source": [
        "## Extract most relevant text from context_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Pl1sAHAq5hIy",
        "outputId": "7be5205a-3844-42c1-a557-75e5fbc0f19b"
      },
      "outputs": [],
      "source": [
        "## Extract most relevant text from context_str\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import torch\n",
        "\n",
        "# 1. Load sentence-transformers model (small, fast on CPU)\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')  # Fast & accurate enough\n",
        "\n",
        "# 2. Function to extract top-k relevant sentences from context based on question\n",
        "def get_top_k_sentences(question, context, k=3):\n",
        "    sentences = sent_tokenize(context)\n",
        "\n",
        "    if not sentences:\n",
        "        return \"\"  # Return empty if context is blank\n",
        "\n",
        "    # Clamp k to number of available sentences\n",
        "    k = min(k, len(sentences))\n",
        "\n",
        "    # Encode question and context sentences\n",
        "    question_embedding = model.encode(question, convert_to_tensor=True)\n",
        "    sentence_embeddings = model.encode(sentences, convert_to_tensor=True)\n",
        "\n",
        "    # Compute semantic similarity\n",
        "    cosine_scores = util.pytorch_cos_sim(question_embedding, sentence_embeddings)[0]\n",
        "\n",
        "    # Get top-k most relevant sentences\n",
        "    top_k_indices = torch.topk(cosine_scores, k=k).indices\n",
        "    selected_sentences = [sentences[i] for i in top_k_indices]\n",
        "\n",
        "    return ' '.join(selected_sentences)\n",
        "\n",
        "\n",
        "# 3. Apply to your dataset\n",
        "# Make sure df_train has columns: 'question', 'context_str'\n",
        "df_train['filtered_context'] = df_train.apply(\n",
        "    lambda row: get_top_k_sentences(row['question'], row['context_str'], k=3), axis=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.to_csv('df_train2.csv', index=False)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                 question  \\\n",
            "117741  Are common genetic variants in the microRNA bi...   \n",
            "164514  Do y-SNPs indicate hybridisation between Europ...   \n",
            "178755  Is genetic polymorphisms ofCYP2A6 andCYP2E1 wi...   \n",
            "51724   Does a background infusion of morphine enhance...   \n",
            "67278   Do neutrophils promote aerogenous spread of lu...   \n",
            "\n",
            "                                              context_str  label  \\\n",
            "117741  Although the role of miRNA in cancer developme...      1   \n",
            "164514  Previous genetic studies of modern and ancient...      1   \n",
            "178755  To elucidate the association between genetic p...      1   \n",
            "51724   To compare the effects of patient-controlled a...      1   \n",
            "67278   Adenocarcinoma with bronchioloalveolar carcino...      0   \n",
            "\n",
            "                                         filtered_context  \n",
            "117741  Although the role of miRNA in cancer developme...  \n",
            "164514  Strikingly, our results do not support the hyp...  \n",
            "178755  To elucidate the association between genetic p...  \n",
            "51724   To compare the effects of patient-controlled a...  \n",
            "67278   We hypothesized that neutrophils could promote...  \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "697"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(df_train.head())\n",
        "len(df_train['context_str'].iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuel5n_J4BSq"
      },
      "source": [
        "## Finetune BioBERT for QA Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5p5jveNfLuSI"
      },
      "source": [
        "Tokenize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "TaIll_GGLrJe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train = pd.read_csv('df_train2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('dmis-lab/biobert-v1.1')\n",
        "\n",
        "def truncate_head_tail(text, tokenizer, max_length):\n",
        "    \"\"\"Truncate the middle of a text to preserve the beginning and end.\"\"\"\n",
        "    tokens = tokenizer.encode(text, add_special_tokens=False)\n",
        "    \n",
        "    if len(tokens) <= max_length:\n",
        "        return tokens\n",
        "    \n",
        "    # Reserve space for special tokens [CLS] and [SEP]\n",
        "    reserved = 2\n",
        "    half = (max_length - reserved) // 2\n",
        "    truncated = tokens[:half] + tokens[-half:]\n",
        "    \n",
        "    return [tokenizer.cls_token_id] + truncated + [tokenizer.sep_token_id]\n",
        "\n",
        "def encode_data(tokenizer, texts, max_length):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in texts:\n",
        "        ids = truncate_head_tail(text, tokenizer, max_length)\n",
        "        mask = [1] * len(ids)\n",
        "\n",
        "        # Pad to max_length\n",
        "        padding_length = max_length - len(ids)\n",
        "        ids += [tokenizer.pad_token_id] * padding_length\n",
        "        mask += [0] * padding_length\n",
        "\n",
        "        input_ids.append(ids)\n",
        "        attention_masks.append(mask)\n",
        "\n",
        "    return torch.tensor(input_ids), torch.tensor(attention_masks)\n",
        "\n",
        "# Use this on your dataset\n",
        "input_ids, attention_mask = encode_data(\n",
        "    tokenizer,\n",
        "    df_train['filtered_context'].tolist(),\n",
        "    max_length=512\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GlVr70sL0jd"
      },
      "source": [
        "Finetuning BioBERT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "mLFaXV3SZZ2M"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3781' max='3781' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3781/3781 44:45, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.797700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.661300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.606500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.607200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.550600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.590400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.566000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.607400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.579600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.582300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.540700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.534100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.568000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.565200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.568300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.541300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.559700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.548300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.554400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.533700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.544200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.507600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.539200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.517600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.523700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.573200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.534900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.538400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.539900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.506200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.519700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.524500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.522500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.490000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.494800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.490300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.471000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3781, training_loss=0.5520996703133007, metrics={'train_runtime': 2685.8895, 'train_samples_per_second': 11.263, 'train_steps_per_second': 1.408, 'total_flos': 7958654659436544.0, 'train_loss': 0.5520996703133007, 'epoch': 0.9999338842975206})"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = AutoModelForSequenceClassification.from_pretrained('dmis-lab/biobert-v1.1', num_labels=3)\n",
        "# Define the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=2,  # lower to fit RAM\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=4,  # effectively 8 if batch size 2\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    save_strategy=\"no\",  # Don't save checkpoints to avoid I/O overhead\n",
        "    load_best_model_at_end=False,\n",
        "    fp16=True,\n",
        ")\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "data = {\n",
        "    'input_ids': input_ids.tolist(),\n",
        "    'attention_mask': attention_mask.tolist(),\n",
        "    'labels': df_train['label'].tolist()\n",
        "}\n",
        "\n",
        "train_ds = Dataset.from_dict(data)\n",
        "\n",
        "# Create the Trainer and start training\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "df_test.to_csv('df_test2.csv', index=False) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'filtered_context'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\ASUS\\Desktop\\Progetto\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'filtered_context'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[24], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Apply same preprocessing as training\u001b[39;00m\n\u001b[0;32m      2\u001b[0m input_ids_test, attention_mask_test \u001b[38;5;241m=\u001b[39m encode_data(\n\u001b[0;32m      3\u001b[0m     tokenizer,\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mdf_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfiltered_context\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[0;32m      5\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m\n\u001b[0;32m      6\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\Desktop\\Progetto\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\Desktop\\Progetto\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'filtered_context'"
          ]
        }
      ],
      "source": [
        "# Apply same preprocessing as training\n",
        "input_ids_test, attention_mask_test = encode_data(\n",
        "    tokenizer,\n",
        "    df_test['filtered_context'].tolist(),\n",
        "    max_length=512\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
