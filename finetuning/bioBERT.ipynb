{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-wL9uiR8v1Y"
      },
      "source": [
        "# BioBERT-based model to classify biomedical QA pairs into yes/no/maybe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF-N-uy88_UI"
      },
      "source": [
        "Two-stage pipeline:\n",
        "  1. Fine-tune BioBERT on labeled + (weighted) artificial data.\n",
        "  2. Evaluate model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8zQ1sd22r2d"
      },
      "source": [
        "## Importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5LB_RWNX2lRQ",
        "outputId": "2a479877-4b1f-4e03-e7b3-4bfc09de0b89"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ASUS\\Desktop\\Progetto\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the labeled, unlabeled, and artificial subsets of PubMedQA\n",
        "# The dataset is split into three subsets:\n",
        "\n",
        "dataset_labeled = load_dataset(\"qiaojin/PubMedQA\", 'pqa_labeled')\n",
        "dataset_unlabeled = load_dataset(\"qiaojin/PubMedQA\", 'pqa_unlabeled')\n",
        "dataset_artificial = load_dataset('qiaojin/PubMedQA', 'pqa_artificial')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vqYmkw5Y3YyT"
      },
      "outputs": [],
      "source": [
        "# Convert the datasets to pandas DataFrames for easier manipulation\n",
        "import pandas as pd\n",
        "\n",
        "df_labeled_original = pd.DataFrame(dataset_labeled['train'])\n",
        "df_unlabeled_original = pd.DataFrame(dataset_unlabeled['train'])\n",
        "df_artificial_original = pd.DataFrame(dataset_artificial['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "f8GZ83hV3dDx"
      },
      "outputs": [],
      "source": [
        "# Make a copy of the original datasets to work on\n",
        "df_labeled = df_labeled_original.copy()\n",
        "df_unlabeled = df_unlabeled_original.copy()\n",
        "df_artificial = df_artificial_original.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2epl7FVv38c-"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6pq0FcwU3_Mz"
      },
      "outputs": [],
      "source": [
        "# Function to merge Question and Contexts into Input\n",
        "def merge_fields(row):\n",
        "    context_text = \" \".join(row['context']['contexts'])\n",
        "    return f\"{context_text}\"\n",
        "\n",
        "# Apply function to all datasets\n",
        "for df in [df_labeled, df_artificial, df_unlabeled]:\n",
        "    df['context_str'] = df.apply(merge_fields, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qQdlnKQY9a_3"
      },
      "outputs": [],
      "source": [
        "label_map = {'yes': 0, 'no': 1, 'maybe': 2}\n",
        "df_labeled['label'] = df_labeled['final_decision'].map(label_map)\n",
        "df_artificial['label'] = df_artificial['final_decision'].map(label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_Z_zo3jQVZ-o"
      },
      "outputs": [],
      "source": [
        "df_labeled_final = df_labeled[['question','context_str', 'label']]\n",
        "df_artificial_final = df_artificial[['question','context_str', 'label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYdouJNJVheE",
        "outputId": "c5c222a0-887d-4bf7-9c28-e9fd03fce3a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "0    552\n",
            "1    338\n",
            "2    110\n",
            "Name: count, dtype: int64\n",
            "label\n",
            "0    196144\n",
            "1     15125\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check class distribution\n",
        "print(df_labeled_final['label'].value_counts())\n",
        "print(df_artificial_final['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YZFDDLsiWRXS"
      },
      "outputs": [],
      "source": [
        "# Balance Artificial Dataset (Downsampling)\n",
        "df_artificial_final = df_artificial_final.groupby('label').sample(n=min(df_artificial_final['label'].value_counts()), random_state=42)\n",
        "# Shuffle the dataset\n",
        "df_artificial_final = df_artificial_final.sample(frac=1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMwFMRXs1EEW",
        "outputId": "161524ee-f832-41d1-9bea-7f233e71ef32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30250"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df_artificial_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IO8dDWK3YP0E"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split df_labeled_final\n",
        "labeled_train, labeled_test = train_test_split(\n",
        "    df_labeled_final,\n",
        "    test_size=0.2,      # 20% for testing\n",
        "    random_state=42,    # for reproducibility\n",
        "    stratify=df_labeled_final['label']  # optional: ensures class distribution is preserved\n",
        ")\n",
        "\n",
        "# Split df_artificial_final\n",
        "artificial_train, artificial_test = train_test_split(\n",
        "    df_artificial_final,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df_artificial_final['label']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7jsLSyKhXMin",
        "outputId": "815c6faf-f74c-4a4f-ee61-f6ce576680cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>context_str</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Increased neutrophil migratory activity after ...</td>\n",
              "      <td>Neutrophil infiltration of the lung is charact...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Are UK radiologists satisfied with the trainin...</td>\n",
              "      <td>A list of telephone numbers of UK hospitals wi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Do patients with rheumatoid arthritis establis...</td>\n",
              "      <td>It is postulated that some aspects of methotre...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A short stay or 23-hour ward in a general and ...</td>\n",
              "      <td>We evaluated the usefulness of a short stay or...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Do family physicians know the costs of medical...</td>\n",
              "      <td>To determine the cost of 46 commonly used inve...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  Increased neutrophil migratory activity after ...   \n",
              "1  Are UK radiologists satisfied with the trainin...   \n",
              "2  Do patients with rheumatoid arthritis establis...   \n",
              "3  A short stay or 23-hour ward in a general and ...   \n",
              "4  Do family physicians know the costs of medical...   \n",
              "\n",
              "                                         context_str  label  \n",
              "0  Neutrophil infiltration of the lung is charact...      0  \n",
              "1  A list of telephone numbers of UK hospitals wi...      1  \n",
              "2  It is postulated that some aspects of methotre...      0  \n",
              "3  We evaluated the usefulness of a short stay or...      0  \n",
              "4  To determine the cost of 46 commonly used inve...      1  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train = pd.concat([labeled_train, artificial_train], ignore_index=True, sort=False)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pprfaz0R1gWZ",
        "outputId": "e1fcd325-4c6d-469a-e458-38f911dde285"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp4VwQoY2fSz",
        "outputId": "5182c48b-876d-4ded-841b-bd423e17f663"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2109"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df_train['context_str'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dabzQA7eY5Qh",
        "outputId": "51225399-0c38-4b9e-a5bc-0291ba52f383"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>context_str</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Are home sampling kits for sexually transmitte...</td>\n",
              "      <td>There is an urgent need to increase opportunis...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Scrotal approach to both palpable and impalpab...</td>\n",
              "      <td>To determine the advantages of scrotal incisio...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Are polymorphisms in oestrogen receptors genes...</td>\n",
              "      <td>Polymorphisms in the oestrogen receptor 1 (ESR...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Do elderly patients benefit from surgery in ad...</td>\n",
              "      <td>Treatment of elderly cancer patients has gaine...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Does route of delivery affect maternal and per...</td>\n",
              "      <td>The route of delivery in eclampsia is controve...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  Are home sampling kits for sexually transmitte...   \n",
              "1  Scrotal approach to both palpable and impalpab...   \n",
              "2  Are polymorphisms in oestrogen receptors genes...   \n",
              "3  Do elderly patients benefit from surgery in ad...   \n",
              "4  Does route of delivery affect maternal and per...   \n",
              "\n",
              "                                         context_str  label  \n",
              "0  There is an urgent need to increase opportunis...      2  \n",
              "1  To determine the advantages of scrotal incisio...      0  \n",
              "2  Polymorphisms in the oestrogen receptor 1 (ESR...      0  \n",
              "3  Treatment of elderly cancer patients has gaine...      1  \n",
              "4  The route of delivery in eclampsia is controve...      1  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test = pd.concat([labeled_test, artificial_test], ignore_index=True, sort=False)\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrHfGj485k18"
      },
      "source": [
        "## Extract most relevant text from context_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Pl1sAHAq5hIy",
        "outputId": "7be5205a-3844-42c1-a557-75e5fbc0f19b"
      },
      "outputs": [],
      "source": [
        "## Extract most relevant text from context_str\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import torch\n",
        "\n",
        "# 1. Load sentence-transformers model (small, fast on CPU)\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')  # Fast & accurate enough\n",
        "\n",
        "# 2. Function to extract top-k relevant sentences from context based on question\n",
        "def get_top_k_sentences(question, context, k=3):\n",
        "    sentences = sent_tokenize(context)\n",
        "\n",
        "    if not sentences:\n",
        "        return \"\"  # Return empty if context is blank\n",
        "\n",
        "    # Clamp k to number of available sentences\n",
        "    k = min(k, len(sentences))\n",
        "\n",
        "    # Encode question and context sentences\n",
        "    question_embedding = model.encode(question, convert_to_tensor=True)\n",
        "    sentence_embeddings = model.encode(sentences, convert_to_tensor=True)\n",
        "\n",
        "    # Compute semantic similarity\n",
        "    cosine_scores = util.pytorch_cos_sim(question_embedding, sentence_embeddings)[0]\n",
        "\n",
        "    # Get top-k most relevant sentences\n",
        "    top_k_indices = torch.topk(cosine_scores, k=k).indices\n",
        "    selected_sentences = [sentences[i] for i in top_k_indices]\n",
        "\n",
        "    return ' '.join(selected_sentences)\n",
        "\n",
        "\n",
        "# 3. Apply to your dataset\n",
        "# Make sure df_train has columns: 'question', 'context_str'\n",
        "df_train['filtered_context'] = df_train.apply(\n",
        "    lambda row: get_top_k_sentences(row['question'], row['context_str'], k=3), axis=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.to_csv('df_train.csv', index=False)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            question  \\\n",
            "0  Increased neutrophil migratory activity after ...   \n",
            "1  Are UK radiologists satisfied with the trainin...   \n",
            "2  Do patients with rheumatoid arthritis establis...   \n",
            "3  A short stay or 23-hour ward in a general and ...   \n",
            "4  Do family physicians know the costs of medical...   \n",
            "\n",
            "                                         context_str  label  \\\n",
            "0  Neutrophil infiltration of the lung is charact...      0   \n",
            "1  A list of telephone numbers of UK hospitals wi...      1   \n",
            "2  It is postulated that some aspects of methotre...      0   \n",
            "3  We evaluated the usefulness of a short stay or...      0   \n",
            "4  To determine the cost of 46 commonly used inve...      1   \n",
            "\n",
            "                                    filtered_context  \n",
            "0  Neutrophils isolated from major trauma patient...  \n",
            "1  Only 52% of departments had a dedicated paedia...  \n",
            "2  To look at the effect of stopping FA supplemen...  \n",
            "3  We evaluated the usefulness of a short stay or...  \n",
            "4  Six hundred family physicians. To determine th...  \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "629"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(df_train.head())\n",
        "len(df_train['filtered_context'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuel5n_J4BSq"
      },
      "source": [
        "## Finetune BioBERT for QA Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5p5jveNfLuSI"
      },
      "source": [
        "Tokenize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaIll_GGLrJe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train = pd.read_csv('df_train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ASUS\\Desktop\\Progetto\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('dmis-lab/biobert-v1.1')\n",
        "\n",
        "def truncate_head_tail(text, tokenizer, max_length):\n",
        "    \"\"\"Truncate the middle of a text to preserve the beginning and end.\"\"\"\n",
        "    tokens = tokenizer.encode(text, add_special_tokens=False)\n",
        "    \n",
        "    if len(tokens) <= max_length:\n",
        "        return tokens\n",
        "    \n",
        "    # Reserve space for special tokens [CLS] and [SEP]\n",
        "    reserved = 2\n",
        "    half = (max_length - reserved) // 2\n",
        "    truncated = tokens[:half] + tokens[-half:]\n",
        "    \n",
        "    return [tokenizer.cls_token_id] + truncated + [tokenizer.sep_token_id]\n",
        "\n",
        "def encode_data(tokenizer, texts, max_length):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in texts:\n",
        "        ids = truncate_head_tail(text, tokenizer, max_length)\n",
        "        mask = [1] * len(ids)\n",
        "\n",
        "        # Pad to max_length\n",
        "        padding_length = max_length - len(ids)\n",
        "        ids += [tokenizer.pad_token_id] * padding_length\n",
        "        mask += [0] * padding_length\n",
        "\n",
        "        input_ids.append(ids)\n",
        "        attention_masks.append(mask)\n",
        "\n",
        "    return torch.tensor(input_ids), torch.tensor(attention_masks)\n",
        "\n",
        "# Use this on your dataset\n",
        "input_ids, attention_mask = encode_data(\n",
        "    tokenizer,\n",
        "    df_train['filtered_context'].tolist(),\n",
        "    max_length=512\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GlVr70sL0jd"
      },
      "source": [
        "Finetuning BioBERT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLFaXV3SZZ2M"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 33:38, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.802700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.654800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.671500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.652000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.639500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.611300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.596400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.579500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.595000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.619800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.604200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.594000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.581400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.591300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.583600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.612400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.532400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.560500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.579000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.558800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.569300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.542600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.546000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.525400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.501500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.567800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.576800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.552900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.541300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.520100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.511900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3125, training_loss=0.5857315985107422, metrics={'train_runtime': 2019.8978, 'train_samples_per_second': 12.377, 'train_steps_per_second': 1.547, 'total_flos': 6577835443200000.0, 'train_loss': 0.5857315985107422, 'epoch': 1.0})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = AutoModelForSequenceClassification.from_pretrained('dmis-lab/biobert-v1.1', num_labels=3)\n",
        "# Define the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=2,  # lower to fit RAM\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=4,  # effectively 8 if batch size 2\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    save_strategy=\"no\",  # Don't save checkpoints to avoid I/O overhead\n",
        "    load_best_model_at_end=False,\n",
        "    fp16=True,\n",
        ")\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "data = {\n",
        "    'input_ids': input_ids.tolist(),\n",
        "    'attention_mask': attention_mask.tolist(),\n",
        "    'labels': df_train['label'].tolist()\n",
        "}\n",
        "\n",
        "train_ds = Dataset.from_dict(data)\n",
        "\n",
        "# Create the Trainer and start training\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        ")\n",
        "trainer.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
